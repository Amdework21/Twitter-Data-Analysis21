{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2e6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main class for clearing Tweeter data sets \n",
    "class Clean_Tweets:\n",
    "    \"\"\"\n",
    "    The PEP8 Standard AMAZING!!!\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print('Automation in Action...!!!')\n",
    "\n",
    "    def add_clean_text(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert original_text values to clean_text values\n",
    "        \"\"\"\n",
    "\n",
    "        df['clean_text'] = df['original_text'].apply(clean_text)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def drop_nullValue_rows(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert original_text values to clean_text values\n",
    "        \"\"\"\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def drop_unwanted_column(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove rows that has column names. This error originated from\n",
    "        the data collection stage.  \n",
    "        \"\"\"\n",
    "        columns = ['created_at', 'source', 'original_text', 'clean_text', 'sentiment', 'polarity', 'subjectivity', 'lang', 'favorite_count', 'retweet_count',\n",
    "                   'original_author', 'screen_count', 'followers_count', 'friends_count', 'possibly_sensitive', 'hashtags', 'user_mentions', 'place', 'place_coord_boundaries']\n",
    "        unwanted_rows = []\n",
    "        for columnName in columns:\n",
    "            unwanted_rows += df[df[columnName] == columnName].index\n",
    "\n",
    "        df.drop(unwanted_rows, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def drop_duplicate(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        drop duplicate rows\n",
    "        \"\"\"\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def convert_to_datetime(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert column to datetime\n",
    "        \"\"\"\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def convert_to_numbers(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        convert columns like polarity, subjectivity, retweet_count\n",
    "        favorite_count etc to numbers\n",
    "        \"\"\"\n",
    "        df[['polarity', 'subjectivity', 'favorite_count', 'retweet_count', 'screen_count', 'followers_count', 'friends_count']] = df[[\n",
    "            'polarity', 'subjectivity', 'favorite_count', 'retweet_count', 'screen_count', 'followers_count', 'friends_count']].apply(pd.to_numeric)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def remove_non_english_tweets(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        remove non english tweets from lang\n",
    "        \"\"\"\n",
    "\n",
    "        index_names = df[df['lang'] != \"en\"].index\n",
    "\n",
    "        df.drop(index_names, inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c877ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(original_text: str) -> str:\n",
    "    cleaned_text = re.sub('\\n', '', original_text)\n",
    "    cleaned_text = re.findall(r'[a-zA-Z]+', cleaned_text)\n",
    "    cleaned_text = \" \".join(cleaned_text)\n",
    "    cleaned_text = re.sub(r'http.*', \"\", cleaned_text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f55ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06ebe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14f516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
